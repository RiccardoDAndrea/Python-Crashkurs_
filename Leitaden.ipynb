{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Jeder Programmierer** \n",
    "\n",
    "stößt irgendwann auf Schwierigkeiten und fühlt sich vielleicht festgefahren – das ist völlig normal. Programmieren, wie so vieles im Leben, ist anfangs herausfordernd, aber mit der Zeit wird es einfacher.\n",
    "\n",
    "Um euch das Leben zu erleichtern und eure Leidenschaft fürs Programmieren auch nach der Blockwoche zu bewahren, habe ich einen Leitfaden erstellt. Dieser soll euch in unsicheren Momenten als Orientierungshilfe dienen, damit ihr nachschlagen könnt, wie bestimmte Dinge funktionieren.\n",
    "\n",
    "Denkt daran: **„Jeder Meister war einmal ein Anfänger.“** Genauso braucht ihr als Anfänger im Programmieren Zeit, um wirklich gut zu werden.\n",
    "\n",
    "Aber keine Sorge – **ihr schafft das!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Leitfaden für Python\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Python Basic Syntax\n",
    "- ### 1.1. Variablen\n",
    "- ### 1.2. Kommentare\n",
    "- ### 1.3. Datentypen\n",
    "- ### 1.4. Operatoren\n",
    "- ### 1.5. Logische Operatoren\n",
    "- ### 1.6. Schleifen\n",
    "    - ### 1.6.1 for loop\n",
    "    - ### 1.6.2 while\n",
    "- ### 1.7 if, elif, else   \n",
    "    - ### 1.7.1 if-Bedigungen\n",
    "    - ### 1.7.2 else-Bedigungen\n",
    "    - ### 1.7.3 Elif-Bedigungen\n",
    "- ### 1.8 Funktionen\n",
    "## 2. Libraries\n",
    "- ### 2.1. Understanding Libraries\n",
    "    - #### 2.1.1 How to read Docs\n",
    "\n",
    "- ### 2.2. Pandas\n",
    "- ### 2.2. Seaborn / Matplotlib \n",
    "- ### 2.3. scikit-learn\n",
    "- ### 2.3. Streamlit \n",
    "\n",
    "\n",
    "## 3. Fehlerbehebungen\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Variablen:\n",
    "----\n",
    "\n",
    "- Variablen können verstanden werden als ein Kontainer für alle möglichen Werte, Daten, Objekte, etc.\n",
    "- Was du nun in der Variable einspeicherst liegt an deinem Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deine Variable enthält den Namen: Max\n",
      "Deine Variable enthält den Nachnamen: Mustermann\n"
     ]
    }
   ],
   "source": [
    "my_firstname = \"Max\"  \n",
    "\n",
    "my_lastname = \"Mustermann\"\n",
    "\n",
    "print(\"Deine Variable enthält den Namen: \" + my_firstname)\n",
    "print(\"Deine Variable enthält den Nachnamen: \" + my_lastname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun wissen wir das die Variable **`my_firstname`** den Wert enthält den du einträgst und die Variable **`my_lastname`** genauso.\n",
    "Wir können nun auf diese Variable zugreifen und diese auch verändern so oft wir wollen.\n",
    "Dabei sind beide Variablen sogenante *String*.\n",
    "String referenziert auf ein *Datentypen* dazu mehr in 1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Kommentare \n",
    "---\n",
    "\n",
    "**Kommentare** sind in der Programmier Welt sehr wichtig. Sie helfen dabei den Code zu verstehen und zu dokumentieren.\n",
    "Kommentare werden in Python mit einem # eingeleitet. Alles was nach dem `#` kommt wird nicht ausgeführt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Das Alter beträgt:  26\n"
     ]
    }
   ],
   "source": [
    "# Folgender Code gibt das Alter der Person wieder\n",
    "Alter = 26     \n",
    "print(\"Das Alter beträgt: \", Alter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Daten Typen\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Vorhandene Datentypen in Python:**\n",
    "\n",
    "<span style=\"color:lightblue\"> **int** </span>: \n",
    "Eine ganze Zahl, wie `5`, `-3` oder `42`.\n",
    "\n",
    "<span style=\"color:lightblue\"> **float** </span>: \n",
    "Eine Dezimalzahl, wie `3.14`, `-0.001` oder `2.0`.\n",
    "\n",
    "<span style=\"color:lightblue\"> **str** </span>: \n",
    "Ein Text, der in Anführungszeichen steht, wie `\"Hallo, Welt!\"` oder `'Python ist toll'`.\n",
    "\n",
    "<span style=\"color:lightblue\"> **bool** </span>: \n",
    "Ein Wert, der entweder `True` (wahr) oder `False` (falsch) ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - int (Absoulte Zahlen)\n",
    "x = 20\n",
    "\n",
    "# - float (Dezimalzahlen)\n",
    "y = 20.5\n",
    "\n",
    "# - str (Strings)\n",
    "Name = \"Das ist ein String der aus Buchstaben besteht und eine Zeichenkette bildet\"\n",
    "\n",
    "# - bool (Booleans)\n",
    "Male = False\n",
    "Female = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:lightblue\"> **list** </span>: \n",
    "\n",
    "Eine Sammlung von Elementen in eckigen Klammern, getrennt durch Kommata, z.B. `[1, 2, 3]` oder `[\"Apfel\", \"Banane\", \"Kirsche\"]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['Apfel', 'Birne', 'Banane', 'Kirsche', 'Erdbeere']\n"
     ]
    }
   ],
   "source": [
    "Früchte = [\"Apfel\", \"Birne\", \"Banane\", \"Kirsche\", \"Erdbeere\"]\n",
    "\n",
    "print(type(Früchte))\n",
    "print(Früchte)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "<span style=\"color:lightblue\"> **Dictionaries** </span>: \n",
    "\n",
    "Ein Wörterbuch mit Schlüssel-Wert-Paaren, das in geschweiften Klammern steht, wie \n",
    "\n",
    "`{\"name\": \"Alice\", \"alter\": 25}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Früchte': 'Erdbeere', 'Menge': 40}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lagerbestand = {\"Früchte\":\"Erdbeere\",\n",
    "                \"Menge\": 40}\n",
    "\n",
    "Lagerbestand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dies war ein kleine Einleitung welche Datentypen es gibt.\n",
    "In den folgeden Kapitel werden wir lernen wie die Datentypen gefiltert, manipuliert werden und vieles mehr\n",
    "\n",
    "| Mehr über **list** und **dictonaries** findest du in ***Kapitel 1.6*** und ***1.7***|\n",
    "|-------------------------------------------------------------------------------------|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Operatoren\n",
    "---\n",
    "\n",
    "Variablen können auch **kombiniert** werden "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addition: 30\n",
      "Subtraktion: 10\n",
      "Multiplikation: 200\n",
      "Division: 2.0\n",
      "Potenz: 10240000000000\n"
     ]
    }
   ],
   "source": [
    "# Eine kleine Übersicht über verschiedene mathematische Operatoren.\n",
    "x = 20\n",
    "y = 10\n",
    "\n",
    "# Addition\n",
    "addition = x + y\n",
    "print(\"Addition:\", addition)\n",
    "\n",
    "# Subtraktion\n",
    "subtraktion = x - y\n",
    "print(\"Subtraktion:\", subtraktion)\n",
    "\n",
    "# Multiplikation\n",
    "multiplikation = x * y\n",
    "print(\"Multiplikation:\", multiplikation)\n",
    "\n",
    "# Division\n",
    "division = x / y\n",
    "print(\"Division:\", division)\n",
    "\n",
    "# Potenzen\n",
    "potenz = x ** y\n",
    "print(\"Potenz:\", potenz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Logische Operatoren\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and Operator: False\n",
      "or Operator: False\n",
      "not Operator: True\n"
     ]
    }
   ],
   "source": [
    "# and (und)\n",
    "und_operator = x < 5 and x < 10\n",
    "print(\"and Operator:\", und_operator)\n",
    "\n",
    "# or (oder)\n",
    "oder_operator = x < 5 or x < 4\n",
    "print(\"or Operator:\", oder_operator)\n",
    "\n",
    "# not (nicht)\n",
    "nicht_operator = not(x < 5 and x < 10)\n",
    "print(\"not Operator:\", nicht_operator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 1.6 Listen (list)\n",
    "---\n",
    "In diesen Abschnitt geht es um die Handhabung mit Listen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:lightblue\"> list </span>:\n",
    "\n",
    "Eine Liste ist eine Datenstruktur in Python, die eine veränderbare, geordnete Sequenz von Elementen darstellt. Jede Eintragung in einer Liste wird als Element bezeichnet. Listen werden durch eckige Klammern [ ] initialisiert.\n",
    "\n",
    "Eine Liste kann Elemente unterschiedlichen Datentyps enthalten. So kann eine Liste beispielsweise nur Strings oder Zahlen enthalten, aber auch verschiedene Datentypen in einer einzigen Liste kombinieren.\n",
    "\n",
    "Eine Liste mit <span style=\"color:lightblue\"> **Strings** </span>:\n",
    "\n",
    "`Früchte = [\"Apfel\", \"Birne\", \"Banane\", \"Kirsche\", \"Erdbeere\"]`\n",
    "\n",
    "Eine Liste mit <span style=\"color:lightblue\"> **Integers** </span>:\n",
    "\n",
    "`menge = [3, 4, 6, 10, 20]`\n",
    "\n",
    "Eine Liste mit <span style=\"color:lightblue\"> **Float** </span>:\n",
    "\n",
    "`Preise = [4.99, 1.99, 6.99, 10.00, 20.95]`\n",
    "\n",
    "Eine Liste mit <span style=\"color:lightblue\"> **Booleans** </span>:\n",
    "\n",
    "`verfügbar = [True, False, True, True, False]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Früchte:  ['Apfel', 'Birne', 'Banane', 'Kirsche', 'Erdbeere']\n",
      "menge:  [3, 4, 6, 10, 20]\n",
      "Preise:  [4.99, 1.99, 6.99, 10.0, 20.95]\n",
      "verfügbar:  [True, False, True, True, False]\n"
     ]
    }
   ],
   "source": [
    "Früchte = [\"Apfel\", \"Birne\", \"Banane\", \"Kirsche\", \"Erdbeere\"]\n",
    "menge = [3, 4, 6, 10, 20]\n",
    "Preise = [4.99, 1.99, 6.99, 10.00, 20.95]\n",
    "verfügbar = [True, False, True, True, False]\n",
    "\n",
    "print(\"Früchte: \", Früchte)\n",
    "print(\"menge: \", menge)\n",
    "print(\"Preise: \", Preise)\n",
    "print(\"verfügbar: \", verfügbar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Index   | 0      | 1      | 2      | 3       | 4         |\n",
    "|---------|--------|--------|--------|---------|-----------|\n",
    "| Element | Apfel  | Birne  | Banane | Kirsche | Erdbeere  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apfel\n",
      "Birne\n",
      "Erdbeere\n"
     ]
    }
   ],
   "source": [
    "print(Früchte[0])   # Apfel Der Index beginnt bei 0 und nicht bei 1\n",
    "print(Früchte[1])   # Birne an der Index Nummer 1 \n",
    "print(Früchte[-1])  # Erdbeere an der Index Nummer -1 also das letzte Element in der Liste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mehrere Werte aus einer Liste extrahieren:\n",
    "<span style=\"color:lightblue\"> **your_list[Inklusiv:Exklusiv]** </span>\n",
    "\n",
    "Mit diesem Code werden die Elemente 2 bis 4 aus der Liste gefiltert. Dabei ist das 2. Element inklusiv und das 5. Element exklusiv:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Banane', 'Kirsche', 'Erdbeere']\n"
     ]
    }
   ],
   "source": [
    "print(Früchte[2:5])  # ['Banane', 'Kirsche'] Der Index 5 wird nicht mitgezählt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit diesem Code werden **alle Elemente** bis zur **Index-Nummer 4** aus der Liste gefiltert. \n",
    "Dabei wird das 2. Element inklusiv und das 5. Element exklusiv betrachtet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Apfel', 'Birne', 'Banane', 'Kirsche']\n",
      "['Banane', 'Kirsche', 'Erdbeere']\n"
     ]
    }
   ],
   "source": [
    "print(Früchte[:4])   # ['Apfel', 'Birne', 'Banane', 'Kirsche']  Die ersten 4 Elemente werden ausgegeben\n",
    "\n",
    "print(Früchte[2:])   # ['Banane', 'Kirsche', 'Erdbeere']        Alle Elemente ab dem Index 2 werden ausgegeben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*WICHTIG:*\n",
    "- In unseren Fall bedeutet das Banane, Kirsche und Erdbeere\n",
    "- Das heißt die 2 (Banane) ist inklusiv und die 5 (Erdbeere) ist exklusiv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Werte hinzufügen**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Element zur einer Liste hinzufügen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ananas hinzufügen: ['Apfel', 'Birne', 'Banane', 'Kirsche', 'Erdbeere', 'Ananas']\n"
     ]
    }
   ],
   "source": [
    "# Element am Ende der Liste hinzufügen\n",
    "Früchte.append('Ananas')\n",
    "print(\"Ananas hinzufügen:\" ,Früchte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Element an einem bestimmten Index hinzufügen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orange an den Index Punkt 5 hinzufügen: ['Apfel', 'Birne', 'Banane', 'Kirsche', 'Erdbeere', 'Orange', 'Ananas']\n"
     ]
    }
   ],
   "source": [
    "# Element an Index Nr. 5 hinzufügen\n",
    "\n",
    "Früchte.insert(5, 'Orange')\n",
    "print(\"Orange an den Index Punkt 5 hinzufügen:\" ,Früchte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Werte ändern:**\n",
    "\n",
    "In Index Nr 1. Ist der Wert *\"Birne\"*\n",
    "\n",
    "`Früchte = [\"Apfel\", \"Birne\", \"Banane\", \"Kirsche\", \"Erdbeere\"]`\n",
    "\n",
    "*\"Birne\"* wird nun erstzt im darunter liegen den Code durch *'Kiwi'* im Index Nr.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Apfel', 'Kiwi', 'Banane', 'Kirsche', 'Erdbeere', 'Orange', 'Ananas']\n"
     ]
    }
   ],
   "source": [
    "# Element in der Liste ändern\n",
    "\n",
    "Früchte[1] = 'Kiwi'\n",
    "print(Früchte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Werte entfernen:**\n",
    "- durch \"remove\" wird der string \"Erdbeere\" entfernt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Apfel', 'Kiwi', 'Banane', 'Kirsche', 'Orange', 'Ananas']\n"
     ]
    }
   ],
   "source": [
    "# Element aus der Liste entfernen\n",
    "\n",
    "Früchte.remove('Erdbeere')\n",
    "print(Früchte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "x = [10, 9, 8, 7, 6, 5, 4, 3, 2, 1]\n",
    "x.sort()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1.7 Dictionaries \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ein Dictionary** ist eine Sammlung, um Daten zu speichern, die in Form von Schlüssel-Wert-Paaren vorliegen.\n",
    "Ein Dictionary üblicherweise in einer Variable gespeichert. In diesem Beispiel nennen wir die Variable `my_dictionary`.\n",
    "Ein **Key (Schlüssel)** kann als Spaltenname verstanden werden, und der **Item (Wert)** referenziert den Inhalt, der in dieser \"Spalte\" stehen soll.\n",
    "\n",
    "Der allgemeine Aufbau eines Dictionaries sieht wie folgt aus:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Möglichkeit\n",
    "- beachte das vor den Doppelpunkte (:) `Key`eingeleitet wird und nach den (:) das `Iteam` folgt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Key1': 'Item1', 'Key2': 'Item2', 'Key3': 'Item3'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dictionary = {\n",
    "    \"Key1\": \"Item1\",\n",
    "    \"Key2\": \"Item2\",\n",
    "    \"Key3\": \"Item3\"\n",
    "}\n",
    "\n",
    "my_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Möglichkeit\n",
    "\n",
    "Die Funktion *`dict`* formatiert automatisch dein Dictionarie im richtig Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Key1': 'Item1', 'Key2': 'Item2', 'Key3': 'Item3'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dictionary = dict(\n",
    "            Key1 = \"Item1\",\n",
    "            Key2 = \"Item2\",\n",
    "            Key3 = \"Item3\"\n",
    ")\n",
    "my_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Key: Dies ist der Name des Schlüssels (z.B. \"Key1\"). Schlüssel müssen unveränderlich sein und können Datentypen wie Strings, Zahlen oder Booleans usw. sein.\n",
    "\n",
    "- Item: Dies ist der Wert, der dem Schlüssel zugeordnet wird (z.B. \"Item1\"). Ein Wert kann jeder beliebige Datentyp sein, wie z.B. ein String, eine Zahl, eine Liste, etc. \n",
    "\n",
    "- *Mehrer Werte können in einer Liste [**strings, booleans, Floats, Integers**] eingesetzt werden das sichert die einfache Manipulation, filterung der Daten.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Früchte': ['Erdbeere', 'Apfel', 'Birne'],\n",
       " 'Menge': [40, 30, 0],\n",
       " 'Verfügbarkeit': [True, True, False]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lagerbestand = {\"Früchte\":[\"Erdbeere\", \"Apfel\", \"Birne\"],\n",
    "                \"Menge\": [40, 30, 0],\n",
    "                \"Verfügbarkeit\": [True, True, False]}\n",
    "                \n",
    "\n",
    "Lagerbestand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Umganz zur Daten Manipulation mit Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Eine Spalte (Key) hinzufügen mit Werte (Item)\n",
    "\n",
    "Im darunter liegenden Code wird zur der bestehenden Variable `Lagerbestand`\n",
    "die Spalte `Verfügbarkeit` mit einer `liste` mit Werten hinzugefügt.\n",
    "Welche Werte du mitgibst ist die überlassen ob es Booleans, Integers, Floats, Strings sind.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dein Aktualisiertes Dictionary:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Früchte': ['Erdbeere', 'Apfel', 'Birne'],\n",
       " 'Menge': [40, 30, 0],\n",
       " 'Verfügbarkeit': [True, True, False],\n",
       " 'Herkunftsland': ['Deutschland', 'Frankreich', 'Dänemark']}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # <- Liste\n",
    "Lagerbestand['Herkunftsland'] = [\"Deutschland\", \"Frankreich\", \"Dänemark\"]\n",
    "\n",
    "print(\"Dein Aktualisiertes Dictionary:\")\n",
    "Lagerbestand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **auf Werte zugereifen**\n",
    "Wenn du ein Dictionary hast mit vielen Keys uns Items kannst du auch nur deine Wunsch Key extrahieren und betrachten dies erfolgt wie folgt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Erdbeere', 'Apfel', 'Birne']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lagerbestand['Früchte']  # Nur die Früchte werden dir angezeigt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Keys entfernen**\n",
    "\n",
    "- `del` entfernt den key und die items deines Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "del Lagerbestand[\"Herkunftsland\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Auf keys zugreifen**\n",
    "\n",
    "- Hier wird nach den Keys gefiltert die Ausgabe sind nur die Keys ohne die Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Früchte', 'Menge', 'Verfügbarkeit'])\n"
     ]
    }
   ],
   "source": [
    "print(Lagerbestand.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **auf Iteams zugreifen**\n",
    "Zu dem jeweiligen Key werden nur die Items herausgegeben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Erdbeere', 'Apfel', 'Birne']\n"
     ]
    }
   ],
   "source": [
    "print(Lagerbestand.get(\"Früchte\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alle items wiedergeben\n",
    "`.values()`gibt dir alle Items in jeden Keys wieder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([['Erdbeere', 'Apfel', 'Birne'], [40, 30, 0], [True, True, False]])\n"
     ]
    }
   ],
   "source": [
    "print(Lagerbestand.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neue werte hinzufügen\n",
    "durch den `Key`kannst du "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lagerbestand[\"Früchte\"].append(\"Kirsche\")\n",
    "Lagerbestand[\"Menge\"].append(30)\n",
    "Lagerbestand[\"Verfügbarkeit\"].append(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Früchte': ['Erdbeere', 'Apfel', 'Birne', 'Kirsche'],\n",
       " 'Menge': [40, 30, 0, 30],\n",
       " 'Verfügbarkeit': [True, True, False, True]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lagerbestand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Schleifen \n",
    "---\n",
    "\n",
    "Loops (Schleifen) in Python ermöglichen es, bestimmte Codeblöcke wiederholt auszuführen. Die beiden gängigsten Arten von Schleifen sind die while-Schleife und die for-Schleife. Mit der **while**-Schleife wird der Codeblock ausgeführt, solange eine angegebene Bedingung erfüllt ist. Mit der **for**-Schleife wird der Codeblock für jedes Element in einer Sequenz, wie z. B. einer Liste, wiederholt ausgeführt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6.1 For-Schleife\n",
    "`for`-Schleifen werden verwendet, um eine Sequenz schrittweise zu durchlaufen, wie zum Beispiel eine Liste, String oder ein Array.\n",
    "\n",
    "\n",
    "- Eine `for`-Schleife kann verwendet werden, um die Elemente einer Liste einzeln zu durchlaufen und zu verarbeiten.\n",
    "\n",
    "- Betrachte das folgende Beispiel, bei dem die Liste früchte durchlaufen wird. Die Liste enthält die Elemente: \n",
    "\n",
    "***Früchte = ['Apfel', 'Kiwi', 'Banane', 'Kirsche', 'Orange', 'Ananas'].***\n",
    "\n",
    "- Die `for`-Schleife hilft uns dabei, jedes Element der Liste nacheinander zu extrahieren und zu verwenden.\n",
    "\n",
    "**Grundlegende Syntax einer `for`-Schleife:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Übliche Syntax für ein Schleifen (loops):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apfel\n",
      "Kiwi\n",
      "Banane\n",
      "Kirsche\n",
      "Orange\n",
      "Ananas\n"
     ]
    }
   ],
   "source": [
    "for frucht in Früchte:\n",
    "    print(frucht)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Achtung:**\n",
    "- Der Datentyp `Früchte` ist eine Liste (`list`).\n",
    "\n",
    "- Die `for`-Schleife durchläuft alle Elemente der Liste und gibt sie als Strings aus.\n",
    "- Sollte es eine `float` oder `int` werden dann dementsprechen `int` oder `float` als Datentypen angepasst\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6.2 While-Schleife\n",
    "---\n",
    "Wie in Punk 1.6.1 bereits beschrieben wird die `while-schleife` solange durch geführt bis die definierte Bedigung erfüllt wird."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In diesem Code-Snippet wird eine `while-Schleife` verwendet, um die Zahlen von 1 bis 5 auszugeben. Zuerst wird die Variable `i` auf den Wert 1 gesetzt. \n",
    "2. Die Schleife prüft dann, ob `i` kleiner als 6 ist. Solange das der Fall ist, wird der Wert von `i` ausgegeben und anschließend um 1 erhöht. \n",
    "3. Dieser Vorgang wiederholt sich, bis `i` den Wert 6 erreicht, wodurch die Schleife endet. Das Ergebnis dieses Codes ist eine aufeinanderfolgende Ausgabe der Zahlen 1 bis 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "while i < 6:\n",
    "  print(i)\n",
    "  i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.7 if, elif, else Bedigungen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7.1 If-Bedigungen\n",
    "Bei einer If Bedigung wird geprüft ob die gegbene Bedigung erfüllt wird. Wenn diese erfüllt wird\n",
    "wird nur der Code unter der If-Bedigung ausgeführt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der Preis ist 10 €\n"
     ]
    }
   ],
   "source": [
    "Preis = 10 # <- hier kannst du ein belibigen Preis eingeben\n",
    "\n",
    "if Preis == 10:\n",
    "    print(\"Der Preis ist 10 €\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7.2 if else-Bedigungen\n",
    "\n",
    "Im nächsten Szenario wird gepruft ob die If-Bedigung wahr ist, wenn die bedigung erfüllt wird führt Sie nur die If-Bedigung.\n",
    "Ist jedoch die If-Bedigung **nicht** erfüllt dann wird **immer** die else-Bedigung erfüllt.\n",
    "\n",
    "\n",
    "**ACHTUNG!**\n",
    "\n",
    "Die else bedigung ist mit vorsicht zu nutzen. Sie wird IMMER ausgeführt sollte die If-Bedigung nicht erfüllt werden.\n",
    "Wenn in deinen Code nur eine IF und ELSE bedigung genutzt wird, wird die ELSE bedigung immer ausgeführt dies kann in gewissen Situationen zu einem unerfwünschten ergebnis führen.\n",
    "\n",
    "\n",
    "- **Daher wird nun zusätzlich die elif bedigung betrachtet.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der Preis beträgt alles andere, aber nicht 10 €\n"
     ]
    }
   ],
   "source": [
    "Preis = 22 # <- hier kannst du ein belibigen Preis eingeben\n",
    "\n",
    "if Preis == 10:\n",
    "    print(\"Der Preis ist 10 €\")\n",
    "else:\n",
    "    print(\"Der Preis beträgt alles andere, aber nicht 10 €\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7.3 if elif else Bedingungen\n",
    "\n",
    "Die elif-Bedingung ist eine weitere Bedingung, die wie die if-Bedingung nur dann ausgeführt wird, wenn die Bedingung erfüllt ist.\n",
    "Das bedeutet, dass zuerst geprüft wird, ob die if-Bedingung erfüllt ist. Wenn nicht, wird geprüft, ob die elif-Bedingung erfüllt ist. Wenn ja, wird dieser Code ausgeführt.\n",
    "\n",
    "- Elif-Bedingungen können so oft erstellt werden, wie notwendig. Beachte aber, dass der Code verständlich und nicht unnötig verkompliziert wird.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der Preis ist 20 €\n"
     ]
    }
   ],
   "source": [
    "Preis = 20 # <- hier kannst du ein beliebigen Preis eingeben\n",
    "\n",
    "if Preis == 10:\n",
    "    print(\"Der Preis ist 10 €\")\n",
    "elif Preis == 20:\n",
    "    print(\"Der Preis ist 20 €\")\n",
    "elif Preis > 10:\n",
    "    print(\"Der Preis ist mehr als 10 €\")\n",
    "elif Preis < 10:\n",
    "    print(\"Der Preis ist weniger als 10 €\")\n",
    "else:\n",
    "    print(\"Der Preis ist mehr als 20 €\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.8 Funktionen\n",
    "---\n",
    "Eine Funktion kann man als ein wiederverwendbares Paket aus Anweisungen sehen. \n",
    "Stellen wir uns vor, du möchtest in einem Programm eine bestimmte Aufgabe immer wieder erledigen – zum Beispiel, eine Zahl zu addieren. Anstatt den gleichen Code immer wieder zu schreiben, kannst du diesen in eine Funktion packen und ihn so oft verwenden, wie du möchtest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie umfangreich deine Funktion wird ist dir überlassen.\n",
    "\n",
    "**Kleiner Tipp**: \n",
    "Beim schreiben einer Funktion füge ein Beschreibung hinzu sowie was die Funktion erwartet Input und Output.\n",
    "**KURZ UND PRÄGNAT KEINE ROMANE!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def addiere(zahl1: int, zahl2: int):\n",
    "\n",
    "    \"\"\"\n",
    "    Addiert zwei Zahlen miteinander\n",
    "\n",
    "    Input: Zwei Integers\n",
    "    Output : Die addition der beiden Zahlen\n",
    "    \"\"\" \n",
    "    summe = zahl1 + zahl2\n",
    "    return summe\n",
    "\n",
    "addiere(4,1) #<- trage hier zahlen zur addition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Libraries\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was ist eine Python-Bibliothek (Libary)?\n",
    "\n",
    "Eine Bibliothek ist eine Sammlung von Code, die alltägliche Aufgaben effizienter macht. \n",
    "\n",
    "- Mit **Pandas** kann man Dataframes Manipulieren, Zeilen hinzufügen, Daten bereiningung und vieles mehr.\n",
    "- Mit **Matplotlib** können mit wenigen Zeilen Code ganze Graphen von Linien, Balken bis hinzu Kerzendiagramme erstellt werden.\n",
    "- Mit **Scikit-learn** wird genutzt für das maschinellen Lernen. Es bietet verschiedene Klassifikations-, Regressions- und Clustering-Algorithmen-\n",
    "- Mit **Streamlit** kannst du Problemlos Webapplikation erstellen werden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um eine Libary zu nutzen, muss diese vorab Installiert werden. Dies erfolgt über den Befehl \n",
    "\n",
    "1. `pip install \"Libary Name\"`\n",
    "\n",
    "2. `%pip install pandas`\n",
    "\n",
    "Nachdem die Libary installiert wurde, kann diese über den Befehl <span style=\"color:orange\"> **import** </span> genutzt werden. \n",
    "Weiterhin kann die Libary auch abgekürzt werden mit <span style=\"color:orange\"> **as** </span>, um den Code übersichtlicher zu gestalten.\n",
    "\n",
    "2. `import pandas as pd`\n",
    "\n",
    "Nach der erfolgreichen Installation kann die Libary wie folgt genutzt werden:\n",
    "\n",
    "Refrenziere die Libary mit dem Kürzel, welches du der Libary gegeben hast.\n",
    "\n",
    "3. `pd.FunktionName(Parameter)`\n",
    "\n",
    "Welche Funktion verfügbar sind wird auf der jeweiligen Homepage Dokumentiert und erklärt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Pandas\n",
    "---\n",
    "Pandas ist eine leistungsstarke Open-Source-Bibliothek in Python, die Werkzeuge für die Arbeit mit strukturierten Daten bietet. Sie ist besonders nützlich für Datenanalyse und -manipulation, da sie einfache, aber effiziente Datenstrukturen wie DataFrames bereitstellt.\n",
    "\n",
    "\n",
    "Installation:\n",
    "Bevor man Pandas verwenden kann, muss die Library installiert werden:\n",
    "\n",
    "- `pip install pandas` beim einer .py Datei\n",
    "- `%pip install pandas` beim einer .ipynb Datei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verwendung\n",
    "Nachdem Pandas installiert ist, kann es in Python wie folgt importiert werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um Daten zu importieren nutzen wir `pd.read_csv()`\n",
    "mit dem befehl help(pd.read_csv) bekommen wir Hilfestellung wie wir die Funktion nutzen können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function read_csv in module pandas.io.parsers.readers:\n",
      "\n",
      "read_csv(filepath_or_buffer: 'FilePath | ReadCsvBuffer[bytes] | ReadCsvBuffer[str]', *, sep: 'str | None | lib.NoDefault' = <no_default>, delimiter: 'str | None | lib.NoDefault' = None, header: \"int | Sequence[int] | None | Literal['infer']\" = 'infer', names: 'Sequence[Hashable] | None | lib.NoDefault' = <no_default>, index_col: 'IndexLabel | Literal[False] | None' = None, usecols: 'UsecolsArgType' = None, dtype: 'DtypeArg | None' = None, engine: 'CSVEngine | None' = None, converters: 'Mapping[Hashable, Callable] | None' = None, true_values: 'list | None' = None, false_values: 'list | None' = None, skipinitialspace: 'bool' = False, skiprows: 'list[int] | int | Callable[[Hashable], bool] | None' = None, skipfooter: 'int' = 0, nrows: 'int | None' = None, na_values: 'Hashable | Iterable[Hashable] | Mapping[Hashable, Iterable[Hashable]] | None' = None, keep_default_na: 'bool' = True, na_filter: 'bool' = True, verbose: 'bool | lib.NoDefault' = <no_default>, skip_blank_lines: 'bool' = True, parse_dates: 'bool | Sequence[Hashable] | None' = None, infer_datetime_format: 'bool | lib.NoDefault' = <no_default>, keep_date_col: 'bool | lib.NoDefault' = <no_default>, date_parser: 'Callable | lib.NoDefault' = <no_default>, date_format: 'str | dict[Hashable, str] | None' = None, dayfirst: 'bool' = False, cache_dates: 'bool' = True, iterator: 'bool' = False, chunksize: 'int | None' = None, compression: 'CompressionOptions' = 'infer', thousands: 'str | None' = None, decimal: 'str' = '.', lineterminator: 'str | None' = None, quotechar: 'str' = '\"', quoting: 'int' = 0, doublequote: 'bool' = True, escapechar: 'str | None' = None, comment: 'str | None' = None, encoding: 'str | None' = None, encoding_errors: 'str | None' = 'strict', dialect: 'str | csv.Dialect | None' = None, on_bad_lines: 'str' = 'error', delim_whitespace: 'bool | lib.NoDefault' = <no_default>, low_memory: 'bool' = True, memory_map: 'bool' = False, float_precision: \"Literal['high', 'legacy'] | None\" = None, storage_options: 'StorageOptions | None' = None, dtype_backend: 'DtypeBackend | lib.NoDefault' = <no_default>) -> 'DataFrame | TextFileReader'\n",
      "    Read a comma-separated values (csv) file into DataFrame.\n",
      "    \n",
      "    Also supports optionally iterating or breaking of the file\n",
      "    into chunks.\n",
      "    \n",
      "    Additional help can be found in the online docs for\n",
      "    `IO Tools <https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html>`_.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    filepath_or_buffer : str, path object or file-like object\n",
      "        Any valid string path is acceptable. The string could be a URL. Valid\n",
      "        URL schemes include http, ftp, s3, gs, and file. For file URLs, a host is\n",
      "        expected. A local file could be: file://localhost/path/to/table.csv.\n",
      "    \n",
      "        If you want to pass in a path object, pandas accepts any ``os.PathLike``.\n",
      "    \n",
      "        By file-like object, we refer to objects with a ``read()`` method, such as\n",
      "        a file handle (e.g. via builtin ``open`` function) or ``StringIO``.\n",
      "    sep : str, default ','\n",
      "        Character or regex pattern to treat as the delimiter. If ``sep=None``, the\n",
      "        C engine cannot automatically detect\n",
      "        the separator, but the Python parsing engine can, meaning the latter will\n",
      "        be used and automatically detect the separator from only the first valid\n",
      "        row of the file by Python's builtin sniffer tool, ``csv.Sniffer``.\n",
      "        In addition, separators longer than 1 character and different from\n",
      "        ``'\\s+'`` will be interpreted as regular expressions and will also force\n",
      "        the use of the Python parsing engine. Note that regex delimiters are prone\n",
      "        to ignoring quoted data. Regex example: ``'\\r\\t'``.\n",
      "    delimiter : str, optional\n",
      "        Alias for ``sep``.\n",
      "    header : int, Sequence of int, 'infer' or None, default 'infer'\n",
      "        Row number(s) containing column labels and marking the start of the\n",
      "        data (zero-indexed). Default behavior is to infer the column names: if no ``names``\n",
      "        are passed the behavior is identical to ``header=0`` and column\n",
      "        names are inferred from the first line of the file, if column\n",
      "        names are passed explicitly to ``names`` then the behavior is identical to\n",
      "        ``header=None``. Explicitly pass ``header=0`` to be able to\n",
      "        replace existing names. The header can be a list of integers that\n",
      "        specify row locations for a :class:`~pandas.MultiIndex` on the columns\n",
      "        e.g. ``[0, 1, 3]``. Intervening rows that are not specified will be\n",
      "        skipped (e.g. 2 in this example is skipped). Note that this\n",
      "        parameter ignores commented lines and empty lines if\n",
      "        ``skip_blank_lines=True``, so ``header=0`` denotes the first line of\n",
      "        data rather than the first line of the file.\n",
      "    names : Sequence of Hashable, optional\n",
      "        Sequence of column labels to apply. If the file contains a header row,\n",
      "        then you should explicitly pass ``header=0`` to override the column names.\n",
      "        Duplicates in this list are not allowed.\n",
      "    index_col : Hashable, Sequence of Hashable or False, optional\n",
      "      Column(s) to use as row label(s), denoted either by column labels or column\n",
      "      indices.  If a sequence of labels or indices is given, :class:`~pandas.MultiIndex`\n",
      "      will be formed for the row labels.\n",
      "    \n",
      "      Note: ``index_col=False`` can be used to force pandas to *not* use the first\n",
      "      column as the index, e.g., when you have a malformed file with delimiters at\n",
      "      the end of each line.\n",
      "    usecols : Sequence of Hashable or Callable, optional\n",
      "        Subset of columns to select, denoted either by column labels or column indices.\n",
      "        If list-like, all elements must either\n",
      "        be positional (i.e. integer indices into the document columns) or strings\n",
      "        that correspond to column names provided either by the user in ``names`` or\n",
      "        inferred from the document header row(s). If ``names`` are given, the document\n",
      "        header row(s) are not taken into account. For example, a valid list-like\n",
      "        ``usecols`` parameter would be ``[0, 1, 2]`` or ``['foo', 'bar', 'baz']``.\n",
      "        Element order is ignored, so ``usecols=[0, 1]`` is the same as ``[1, 0]``.\n",
      "        To instantiate a :class:`~pandas.DataFrame` from ``data`` with element order\n",
      "        preserved use ``pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']]``\n",
      "        for columns in ``['foo', 'bar']`` order or\n",
      "        ``pd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']]``\n",
      "        for ``['bar', 'foo']`` order.\n",
      "    \n",
      "        If callable, the callable function will be evaluated against the column\n",
      "        names, returning names where the callable function evaluates to ``True``. An\n",
      "        example of a valid callable argument would be ``lambda x: x.upper() in\n",
      "        ['AAA', 'BBB', 'DDD']``. Using this parameter results in much faster\n",
      "        parsing time and lower memory usage.\n",
      "    dtype : dtype or dict of {Hashable : dtype}, optional\n",
      "        Data type(s) to apply to either the whole dataset or individual columns.\n",
      "        E.g., ``{'a': np.float64, 'b': np.int32, 'c': 'Int64'}``\n",
      "        Use ``str`` or ``object`` together with suitable ``na_values`` settings\n",
      "        to preserve and not interpret ``dtype``.\n",
      "        If ``converters`` are specified, they will be applied INSTEAD\n",
      "        of ``dtype`` conversion.\n",
      "    \n",
      "        .. versionadded:: 1.5.0\n",
      "    \n",
      "            Support for ``defaultdict`` was added. Specify a ``defaultdict`` as input where\n",
      "            the default determines the ``dtype`` of the columns which are not explicitly\n",
      "            listed.\n",
      "    engine : {'c', 'python', 'pyarrow'}, optional\n",
      "        Parser engine to use. The C and pyarrow engines are faster, while the python engine\n",
      "        is currently more feature-complete. Multithreading is currently only supported by\n",
      "        the pyarrow engine.\n",
      "    \n",
      "        .. versionadded:: 1.4.0\n",
      "    \n",
      "            The 'pyarrow' engine was added as an *experimental* engine, and some features\n",
      "            are unsupported, or may not work correctly, with this engine.\n",
      "    converters : dict of {Hashable : Callable}, optional\n",
      "        Functions for converting values in specified columns. Keys can either\n",
      "        be column labels or column indices.\n",
      "    true_values : list, optional\n",
      "        Values to consider as ``True`` in addition to case-insensitive variants of 'True'.\n",
      "    false_values : list, optional\n",
      "        Values to consider as ``False`` in addition to case-insensitive variants of 'False'.\n",
      "    skipinitialspace : bool, default False\n",
      "        Skip spaces after delimiter.\n",
      "    skiprows : int, list of int or Callable, optional\n",
      "        Line numbers to skip (0-indexed) or number of lines to skip (``int``)\n",
      "        at the start of the file.\n",
      "    \n",
      "        If callable, the callable function will be evaluated against the row\n",
      "        indices, returning ``True`` if the row should be skipped and ``False`` otherwise.\n",
      "        An example of a valid callable argument would be ``lambda x: x in [0, 2]``.\n",
      "    skipfooter : int, default 0\n",
      "        Number of lines at bottom of file to skip (Unsupported with ``engine='c'``).\n",
      "    nrows : int, optional\n",
      "        Number of rows of file to read. Useful for reading pieces of large files.\n",
      "    na_values : Hashable, Iterable of Hashable or dict of {Hashable : Iterable}, optional\n",
      "        Additional strings to recognize as ``NA``/``NaN``. If ``dict`` passed, specific\n",
      "        per-column ``NA`` values.  By default the following values are interpreted as\n",
      "        ``NaN``: \" \", \"#N/A\", \"#N/A N/A\", \"#NA\", \"-1.#IND\", \"-1.#QNAN\", \"-NaN\", \"-nan\",\n",
      "        \"1.#IND\", \"1.#QNAN\", \"<NA>\", \"N/A\", \"NA\", \"NULL\", \"NaN\", \"None\",\n",
      "        \"n/a\", \"nan\", \"null \".\n",
      "    \n",
      "    keep_default_na : bool, default True\n",
      "        Whether or not to include the default ``NaN`` values when parsing the data.\n",
      "        Depending on whether ``na_values`` is passed in, the behavior is as follows:\n",
      "    \n",
      "        * If ``keep_default_na`` is ``True``, and ``na_values`` are specified, ``na_values``\n",
      "          is appended to the default ``NaN`` values used for parsing.\n",
      "        * If ``keep_default_na`` is ``True``, and ``na_values`` are not specified, only\n",
      "          the default ``NaN`` values are used for parsing.\n",
      "        * If ``keep_default_na`` is ``False``, and ``na_values`` are specified, only\n",
      "          the ``NaN`` values specified ``na_values`` are used for parsing.\n",
      "        * If ``keep_default_na`` is ``False``, and ``na_values`` are not specified, no\n",
      "          strings will be parsed as ``NaN``.\n",
      "    \n",
      "        Note that if ``na_filter`` is passed in as ``False``, the ``keep_default_na`` and\n",
      "        ``na_values`` parameters will be ignored.\n",
      "    na_filter : bool, default True\n",
      "        Detect missing value markers (empty strings and the value of ``na_values``). In\n",
      "        data without any ``NA`` values, passing ``na_filter=False`` can improve the\n",
      "        performance of reading a large file.\n",
      "    verbose : bool, default False\n",
      "        Indicate number of ``NA`` values placed in non-numeric columns.\n",
      "    \n",
      "        .. deprecated:: 2.2.0\n",
      "    skip_blank_lines : bool, default True\n",
      "        If ``True``, skip over blank lines rather than interpreting as ``NaN`` values.\n",
      "    parse_dates : bool, list of Hashable, list of lists or dict of {Hashable : list}, default False\n",
      "        The behavior is as follows:\n",
      "    \n",
      "        * ``bool``. If ``True`` -> try parsing the index. Note: Automatically set to\n",
      "          ``True`` if ``date_format`` or ``date_parser`` arguments have been passed.\n",
      "        * ``list`` of ``int`` or names. e.g. If ``[1, 2, 3]`` -> try parsing columns 1, 2, 3\n",
      "          each as a separate date column.\n",
      "        * ``list`` of ``list``. e.g.  If ``[[1, 3]]`` -> combine columns 1 and 3 and parse\n",
      "          as a single date column. Values are joined with a space before parsing.\n",
      "        * ``dict``, e.g. ``{'foo' : [1, 3]}`` -> parse columns 1, 3 as date and call\n",
      "          result 'foo'. Values are joined with a space before parsing.\n",
      "    \n",
      "        If a column or index cannot be represented as an array of ``datetime``,\n",
      "        say because of an unparsable value or a mixture of timezones, the column\n",
      "        or index will be returned unaltered as an ``object`` data type. For\n",
      "        non-standard ``datetime`` parsing, use :func:`~pandas.to_datetime` after\n",
      "        :func:`~pandas.read_csv`.\n",
      "    \n",
      "        Note: A fast-path exists for iso8601-formatted dates.\n",
      "    infer_datetime_format : bool, default False\n",
      "        If ``True`` and ``parse_dates`` is enabled, pandas will attempt to infer the\n",
      "        format of the ``datetime`` strings in the columns, and if it can be inferred,\n",
      "        switch to a faster method of parsing them. In some cases this can increase\n",
      "        the parsing speed by 5-10x.\n",
      "    \n",
      "        .. deprecated:: 2.0.0\n",
      "            A strict version of this argument is now the default, passing it has no effect.\n",
      "    \n",
      "    keep_date_col : bool, default False\n",
      "        If ``True`` and ``parse_dates`` specifies combining multiple columns then\n",
      "        keep the original columns.\n",
      "    date_parser : Callable, optional\n",
      "        Function to use for converting a sequence of string columns to an array of\n",
      "        ``datetime`` instances. The default uses ``dateutil.parser.parser`` to do the\n",
      "        conversion. pandas will try to call ``date_parser`` in three different ways,\n",
      "        advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
      "        (as defined by ``parse_dates``) as arguments; 2) concatenate (row-wise) the\n",
      "        string values from the columns defined by ``parse_dates`` into a single array\n",
      "        and pass that; and 3) call ``date_parser`` once for each row using one or\n",
      "        more strings (corresponding to the columns defined by ``parse_dates``) as\n",
      "        arguments.\n",
      "    \n",
      "        .. deprecated:: 2.0.0\n",
      "           Use ``date_format`` instead, or read in as ``object`` and then apply\n",
      "           :func:`~pandas.to_datetime` as-needed.\n",
      "    date_format : str or dict of column -> format, optional\n",
      "        Format to use for parsing dates when used in conjunction with ``parse_dates``.\n",
      "        The strftime to parse time, e.g. :const:`\"%d/%m/%Y\"`. See\n",
      "        `strftime documentation\n",
      "        <https://docs.python.org/3/library/datetime.html\n",
      "        #strftime-and-strptime-behavior>`_ for more information on choices, though\n",
      "        note that :const:`\"%f\"` will parse all the way up to nanoseconds.\n",
      "        You can also pass:\n",
      "    \n",
      "        - \"ISO8601\", to parse any `ISO8601 <https://en.wikipedia.org/wiki/ISO_8601>`_\n",
      "            time string (not necessarily in exactly the same format);\n",
      "        - \"mixed\", to infer the format for each element individually. This is risky,\n",
      "            and you should probably use it along with `dayfirst`.\n",
      "    \n",
      "        .. versionadded:: 2.0.0\n",
      "    dayfirst : bool, default False\n",
      "        DD/MM format dates, international and European format.\n",
      "    cache_dates : bool, default True\n",
      "        If ``True``, use a cache of unique, converted dates to apply the ``datetime``\n",
      "        conversion. May produce significant speed-up when parsing duplicate\n",
      "        date strings, especially ones with timezone offsets.\n",
      "    \n",
      "    iterator : bool, default False\n",
      "        Return ``TextFileReader`` object for iteration or getting chunks with\n",
      "        ``get_chunk()``.\n",
      "    chunksize : int, optional\n",
      "        Number of lines to read from the file per chunk. Passing a value will cause the\n",
      "        function to return a ``TextFileReader`` object for iteration.\n",
      "        See the `IO Tools docs\n",
      "        <https://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking>`_\n",
      "        for more information on ``iterator`` and ``chunksize``.\n",
      "    \n",
      "    compression : str or dict, default 'infer'\n",
      "        For on-the-fly decompression of on-disk data. If 'infer' and 'filepath_or_buffer' is\n",
      "        path-like, then detect compression from the following extensions: '.gz',\n",
      "        '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      "        (otherwise no compression).\n",
      "        If using 'zip' or 'tar', the ZIP file must contain only one data file to be read in.\n",
      "        Set to ``None`` for no decompression.\n",
      "        Can also be a dict with key ``'method'`` set\n",
      "        to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'xz'``, ``'tar'``} and\n",
      "        other key-value pairs are forwarded to\n",
      "        ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      "        ``bz2.BZ2File``, ``zstandard.ZstdDecompressor``, ``lzma.LZMAFile`` or\n",
      "        ``tarfile.TarFile``, respectively.\n",
      "        As an example, the following could be passed for Zstandard decompression using a\n",
      "        custom compression dictionary:\n",
      "        ``compression={'method': 'zstd', 'dict_data': my_compression_dict}``.\n",
      "    \n",
      "        .. versionadded:: 1.5.0\n",
      "            Added support for `.tar` files.\n",
      "    \n",
      "        .. versionchanged:: 1.4.0 Zstandard support.\n",
      "    \n",
      "    thousands : str (length 1), optional\n",
      "        Character acting as the thousands separator in numerical values.\n",
      "    decimal : str (length 1), default '.'\n",
      "        Character to recognize as decimal point (e.g., use ',' for European data).\n",
      "    lineterminator : str (length 1), optional\n",
      "        Character used to denote a line break. Only valid with C parser.\n",
      "    quotechar : str (length 1), optional\n",
      "        Character used to denote the start and end of a quoted item. Quoted\n",
      "        items can include the ``delimiter`` and it will be ignored.\n",
      "    quoting : {0 or csv.QUOTE_MINIMAL, 1 or csv.QUOTE_ALL, 2 or csv.QUOTE_NONNUMERIC, 3 or csv.QUOTE_NONE}, default csv.QUOTE_MINIMAL\n",
      "        Control field quoting behavior per ``csv.QUOTE_*`` constants. Default is\n",
      "        ``csv.QUOTE_MINIMAL`` (i.e., 0) which implies that only fields containing special\n",
      "        characters are quoted (e.g., characters defined in ``quotechar``, ``delimiter``,\n",
      "        or ``lineterminator``.\n",
      "    doublequote : bool, default True\n",
      "       When ``quotechar`` is specified and ``quoting`` is not ``QUOTE_NONE``, indicate\n",
      "       whether or not to interpret two consecutive ``quotechar`` elements INSIDE a\n",
      "       field as a single ``quotechar`` element.\n",
      "    escapechar : str (length 1), optional\n",
      "        Character used to escape other characters.\n",
      "    comment : str (length 1), optional\n",
      "        Character indicating that the remainder of line should not be parsed.\n",
      "        If found at the beginning\n",
      "        of a line, the line will be ignored altogether. This parameter must be a\n",
      "        single character. Like empty lines (as long as ``skip_blank_lines=True``),\n",
      "        fully commented lines are ignored by the parameter ``header`` but not by\n",
      "        ``skiprows``. For example, if ``comment='#'``, parsing\n",
      "        ``#empty\\na,b,c\\n1,2,3`` with ``header=0`` will result in ``'a,b,c'`` being\n",
      "        treated as the header.\n",
      "    encoding : str, optional, default 'utf-8'\n",
      "        Encoding to use for UTF when reading/writing (ex. ``'utf-8'``). `List of Python\n",
      "        standard encodings\n",
      "        <https://docs.python.org/3/library/codecs.html#standard-encodings>`_ .\n",
      "    \n",
      "    encoding_errors : str, optional, default 'strict'\n",
      "        How encoding errors are treated. `List of possible values\n",
      "        <https://docs.python.org/3/library/codecs.html#error-handlers>`_ .\n",
      "    \n",
      "        .. versionadded:: 1.3.0\n",
      "    \n",
      "    dialect : str or csv.Dialect, optional\n",
      "        If provided, this parameter will override values (default or not) for the\n",
      "        following parameters: ``delimiter``, ``doublequote``, ``escapechar``,\n",
      "        ``skipinitialspace``, ``quotechar``, and ``quoting``. If it is necessary to\n",
      "        override values, a ``ParserWarning`` will be issued. See ``csv.Dialect``\n",
      "        documentation for more details.\n",
      "    on_bad_lines : {'error', 'warn', 'skip'} or Callable, default 'error'\n",
      "        Specifies what to do upon encountering a bad line (a line with too many fields).\n",
      "        Allowed values are :\n",
      "    \n",
      "        - ``'error'``, raise an Exception when a bad line is encountered.\n",
      "        - ``'warn'``, raise a warning when a bad line is encountered and skip that line.\n",
      "        - ``'skip'``, skip bad lines without raising or warning when they are encountered.\n",
      "    \n",
      "        .. versionadded:: 1.3.0\n",
      "    \n",
      "        .. versionadded:: 1.4.0\n",
      "    \n",
      "            - Callable, function with signature\n",
      "              ``(bad_line: list[str]) -> list[str] | None`` that will process a single\n",
      "              bad line. ``bad_line`` is a list of strings split by the ``sep``.\n",
      "              If the function returns ``None``, the bad line will be ignored.\n",
      "              If the function returns a new ``list`` of strings with more elements than\n",
      "              expected, a ``ParserWarning`` will be emitted while dropping extra elements.\n",
      "              Only supported when ``engine='python'``\n",
      "    \n",
      "        .. versionchanged:: 2.2.0\n",
      "    \n",
      "            - Callable, function with signature\n",
      "              as described in `pyarrow documentation\n",
      "              <https://arrow.apache.org/docs/python/generated/pyarrow.csv.ParseOptions.html\n",
      "              #pyarrow.csv.ParseOptions.invalid_row_handler>`_ when ``engine='pyarrow'``\n",
      "    \n",
      "    delim_whitespace : bool, default False\n",
      "        Specifies whether or not whitespace (e.g. ``' '`` or ``'\\t'``) will be\n",
      "        used as the ``sep`` delimiter. Equivalent to setting ``sep='\\s+'``. If this option\n",
      "        is set to ``True``, nothing should be passed in for the ``delimiter``\n",
      "        parameter.\n",
      "    \n",
      "        .. deprecated:: 2.2.0\n",
      "            Use ``sep=\"\\s+\"`` instead.\n",
      "    low_memory : bool, default True\n",
      "        Internally process the file in chunks, resulting in lower memory use\n",
      "        while parsing, but possibly mixed type inference.  To ensure no mixed\n",
      "        types either set ``False``, or specify the type with the ``dtype`` parameter.\n",
      "        Note that the entire file is read into a single :class:`~pandas.DataFrame`\n",
      "        regardless, use the ``chunksize`` or ``iterator`` parameter to return the data in\n",
      "        chunks. (Only valid with C parser).\n",
      "    memory_map : bool, default False\n",
      "        If a filepath is provided for ``filepath_or_buffer``, map the file object\n",
      "        directly onto memory and access the data directly from there. Using this\n",
      "        option can improve performance because there is no longer any I/O overhead.\n",
      "    float_precision : {'high', 'legacy', 'round_trip'}, optional\n",
      "        Specifies which converter the C engine should use for floating-point\n",
      "        values. The options are ``None`` or ``'high'`` for the ordinary converter,\n",
      "        ``'legacy'`` for the original lower precision pandas converter, and\n",
      "        ``'round_trip'`` for the round-trip converter.\n",
      "    \n",
      "    storage_options : dict, optional\n",
      "        Extra options that make sense for a particular storage connection, e.g.\n",
      "        host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      "        are forwarded to ``urllib.request.Request`` as header options. For other\n",
      "        URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      "        forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      "        details, and for more examples on storage options refer `here\n",
      "        <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      "        highlight=storage_options#reading-writing-remote-files>`_.\n",
      "    \n",
      "    dtype_backend : {'numpy_nullable', 'pyarrow'}, default 'numpy_nullable'\n",
      "        Back-end data type applied to the resultant :class:`DataFrame`\n",
      "        (still experimental). Behaviour is as follows:\n",
      "    \n",
      "        * ``\"numpy_nullable\"``: returns nullable-dtype-backed :class:`DataFrame`\n",
      "          (default).\n",
      "        * ``\"pyarrow\"``: returns pyarrow-backed nullable :class:`ArrowDtype`\n",
      "          DataFrame.\n",
      "    \n",
      "        .. versionadded:: 2.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame or TextFileReader\n",
      "        A comma-separated values (csv) file is returned as two-dimensional\n",
      "        data structure with labeled axes.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
      "    read_table : Read general delimited file into DataFrame.\n",
      "    read_fwf : Read a table of fixed-width formatted lines into DataFrame.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> pd.read_csv('data.csv')  # doctest: +SKIP\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.read_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn die Anleitung aufmerksam gelesen wird ist der erster Parameter:\n",
    "\n",
    "`filepath_or_buffer = str, path object or file-like object`\n",
    "\n",
    "\"Any valid string path is acceptable.\"\n",
    "Das bedeutet gib den Parameter wo deine Datei liegt indem Fall eine comma seprated Value (.csv) als String(str),\n",
    "\n",
    "- ***filepath_or_buffer: \"Desktop/Daten/dein_Datei_namem.csv\"***\n",
    "\n",
    "\n",
    "`Seprator - sep: str, default ‘,’`\n",
    "Weiterhin um die Datei richtig einzulesen muss man ein Seprator mit eingeben in unseren Fall ist es eine comma seprated Value (.csv) als Dateiformat also macht es Sinn ein Komme zusetzten als String.\n",
    "\n",
    "- ***sep = \",\"***\n",
    "\n",
    "Zusammengefasst wäre der Code wie folgt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_csv(filepath_or_buffer = \"Desktop/Daten/deine_Datei_Namen_einfügen.csv\",\n",
    "#           sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filepath_or_buffer = \"Data/wage.csv\",\n",
    "            sep=\"\\t\") \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Beachte hier wird die CSV Tabelle in die Variable df eingespeichert. Somit müssen wir den ganze Code nicht immer durch führen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.head():\n",
    "\n",
    "Ist eine weitere Pandas Funktion um die Daten zubetrachten. Dabei werden die ersten 5 Zeilen angezeigt\n",
    "\n",
    "Sollte hier in die df.head() Funktion ein integer mitgeben werden wie 20 werden dementsprechend 20 Zeilen betrachtet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()           # <- Die ersten 5 Zeilen\n",
    "# df.head(20)       # <- Die ersten 20 Zeilen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um ein besseres Verständis für deine Daten zubekommen hilft die Funktion:\n",
    "`df.describe()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Datensatz enthält Informationen über **998 Personen**.\n",
    "\n",
    "- Der **durchschnittliche Stundenlohn** beträgt etwa **10,23 USD**, wobei der niedrigste Lohn **2,07 USD** und der höchste **60,19 USD** beträgt.\n",
    "- Im Durchschnitt haben die Personen **13,29 Jahre Bildung** abgeschlossen, wobei die Ausbildungsspanne von **1 Jahr** bis zu **18 Jahren** reicht.\n",
    "- Die **durchschnittliche Berufserfahrung** liegt bei **18,79 Jahren**, wobei einige Personen **keine Berufserfahrung** haben und andere bis zu **52 Jahre** Berufserfahrung vorweisen können.\n",
    "- **Etwa 81% der Personen** leben in **städtischen Gebieten**, während die restlichen **19%** in ländlichen Gegenden wohnen.\n",
    "- Die Verteilung der Stundenlöhne zeigt, dass **50% der Löhne** zwischen **5,53 USD** und **12,84 USD** liegen, mit einem Medianlohn von **8,83 USD**.\n",
    "- Hinsichtlich der Bildung haben **50% der Personen** zwischen **12 und 16 Jahren** Ausbildung, mit einem Median von **13 Jahren**.\n",
    "- Die Berufserfahrung variiert stark, wobei **50% der Personen** zwischen **10 und 26 Jahren** Erfahrung haben, mit einem Median von **18 Jahren**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten filterung mit Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um Daten zu filtern starten wir mit dem Dataframe wo die Datengespeichert werden.\n",
    "\n",
    "*df_filtered = df[df[\"wage\"] > 12.00]*\n",
    "\n",
    "1. *`df:`* Dies ist der ursprüngliche DataFrame, der alle Daten enthält.\n",
    "2. *`df[\"wage\"]`*: Hier geben wir die Spalte an, aus der die Daten gefiltert werden sollen. In diesem Fall wird die Spalte `wage` (Lohn) verwendet.\n",
    "3. `*df[df[\"wage\"] > 12.00]*`: Der Vergleichsoperator `*> 12.00*` filtert alle Zeilen, in denen der Lohn höher als 12.00 ist. Das Ergebnis ist ein neuer DataFrame df_filtered, der nur die Daten enthält, bei denen der Lohn über 12.00 liegt.\n",
    "\n",
    "Um Daten zufiltern nutzen wir folgenden Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[df[\"wage\"] > 12.00].round(2) \n",
    "df_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_educ = df[(df[\"wage\"] > 12.00) & \n",
    "                    (df[\"educ\"] == 13)].round(2)\n",
    "\n",
    "\n",
    "df_filtered_educ.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Matplotlib / Seaborn\n",
    "---\n",
    "\n",
    "Matplotlib ist eine leistungsstarke Bibliothek zur Visualisierung von Daten in Python. Mit ihr lassen sich eine Vielzahl von Diagrammen und Plots erstellen, wie Linien-, Balken-, und Streudiagramme. Sie wird häufig für die Erstellung von 2D-Grafiken verwendet und bietet umfangreiche Anpassungsmöglichkeiten.\n",
    "\n",
    "Detaillierte Informationen und Anleitungen findest du in der offiziellen Dokumentation:\n",
    "\n",
    "\n",
    "- [Matplotlib-Dokumentation](https://matplotlib.org/stable/)\n",
    "\n",
    "- [Seaborn-Dokumentation](https://seaborn.pydata.org/api.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install matplotlib\n",
    "#%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Histogramm\n",
    "\n",
    "Um ein Histogramm zu erstellen nutzen wir die Funktion \n",
    "\n",
    "[`sns.histplot()`](https://seaborn.pydata.org/generated/seaborn.histplot.html)\n",
    "\n",
    "Folgende Parameter werden dabei mit gegeben:\n",
    "\n",
    "`plt.hist(data=df, x=Spalte_zur_Visualisierung, bins=10)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Offiziele Dokumentation :**\n",
    "\n",
    "\n",
    "**1. x:**\n",
    "\n",
    "- array or sequence of (n,) arrays Input values, this takes either a single array or a sequence of arrays which are not required to be of the same length.\n",
    "\n",
    "*Erklärung:*\n",
    "\n",
    "- Welche Spalte soll visualisert werden\n",
    "\n",
    "**2. bins:**   \n",
    "\n",
    "- `int` or sequence or `str`, default: rcParams[\"hist.bins\"] (default: 10) If bins is an `integer`, it defines the number of equal-width bins in the range.\n",
    "\n",
    "*Erklärung:*\n",
    "\n",
    "- Wie viele Klassen sollen visualisert werden, dabei wird ein Interger mitgegeben.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df, x=\"wage\", bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die aussagekraft des Graphen zu steigern kann jeder Graph auf vielen wegen personalisiert werden.\n",
    "Dabei können folgende Funktion verwendet:\n",
    "\n",
    "- [`plt.title(\"Dein Titel\", loc=\"Platzierung festlegen\")`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.title.html)\n",
    "- [`plt.xlabel(\"Title der X-Achse\")`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.xlabel.html)\n",
    "- [`plt.ylabel(\"Title der Y-Achse\")`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.ylabel.html)\n",
    "\n",
    "*weitere hilfreiche Funktion:*\n",
    "\n",
    "- [`plt.xticks()`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.xticks.html)\n",
    "- [`plt.yticks()`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.yticks.html)        \n",
    "- [`plt.legend(loc=\"upper right\", labels=[\"median_house_value\"])`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.legend.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df, x=\"wage\", bins=30)\n",
    "plt.title(label = \"Verteilung der Löhne\")  \n",
    "plt.xlabel(xlabel = \"Lohn (wage)\", loc=\"right\")        \n",
    "plt.ylabel(ylabel= \"Anzahl\", loc='top')               \n",
    "plt.legend(loc=\"upper right\", labels=[\"wage\"]) \n",
    "plt.grid(False)  \n",
    "plt.savefig(\"Data/wage_distribution.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im folgenden Beispiel wird ein einfacher Scatterplot erstellt.\n",
    "Dabei wird der Scatterplot durch `plt.scatter()` erstellt. \n",
    "1. **`x`**: welche Spalte aus deinem Dataframe soll angezeigt werden auf der *X-Achse*\n",
    "2. **`y`**: welche Spalte aus deinem Dataframe soll angezeigt werden auf der *Y-Achse*\n",
    "\n",
    "Und wie im Beispiel zuvor individualisieren wird den Scatter plot durch die passenden beschriftungen\n",
    "und zeigen ihn dann durch `plt.show()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df, x = \"educ\", y = \"wage\")\n",
    "plt.title(\"Streudiagramm: Ausbildung vs Lohn\")  \n",
    "plt.xlabel(\"Ausbildung (Jahre)\")               \n",
    "plt.ylabel(\"Lohn (Dollar)\")                    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 Scitkit-learn\n",
    "\n",
    "Scitkit-learn ist eine open Source Libary zum maschinellen Lernen. Es bietet verschiedene Klassifikations-, Regressions- und Clustering-Algorithmen, darunter Support-Vektor-Maschinen, Random Forest, Gradient Boosting (wie XGBoost), k-means und DBSCAN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um eine Regression durchzuführen, müssen zunächst die abhängige Variable (y) und die unabhängige Variable (x) definiert werden.\n",
    "\n",
    "- Die abhängige Variable (y) ist die Größe, die wir vorhersagen möchten.\n",
    "- Die unabhängige Variable (x) ist die Größe, die wir zur Vorhersage von y verwenden.\n",
    "\n",
    "In einer linearen Regression beispielsweise versucht das Modell, basierend auf den Werten der unabhängigen Variable (x), eine Beziehung zu y herzustellen, um Vorhersagen zu treffen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"wage\"]\n",
    "X = df[[\"educ\", \"exper\", \"metro\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun importieren wir die `train_test_split` Funktion aus dem Modul model_selection von scikit-learn.\n",
    "Dies erlaubt uns, die Daten in *Trainings-* und *Testdaten* zu unterteilen.\n",
    "\n",
    "Die Funktion train_test_split benötigt die folgenden Argumente:\n",
    "\n",
    "- `X`: Die unabhängigen Variablen\n",
    "- `y`: Die abhängige Variable\n",
    "- `test_size`: Der Anteil der Testdaten (hier 20%)  \n",
    "- `random_state`: Ein Zufallsgenerator, um die Daten zu mischen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "\n",
    "# Ausgabe der Dimensionen des Trainings- und Testdatensatzes\n",
    "print(\"Der Trainingsdatensatz für die unabhängigen Variablen (X) besitzt\", X_train.shape[0], \"Reihen und\", X_train.shape[1], \"Spalten.\")\n",
    "print(\"Der Trainingsdatensatz für die abhängige Variable (y) besitzt\", y_train.shape[0], \"Reihen.\")\n",
    "\n",
    "print(\"Der Testdatensatz für die unabhängigen Variablen (X) besitzt\", X_test.shape[0], \"Reihen und\", X_test.shape[1], \"Spalten.\")\n",
    "print(\"Der Testdatensatz für die abhängige Variable (y) besitzt\", y_test.shape[0], \"Reihen.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit der Importierung der Funktion `LinearRegression` aus dem Modul `sklearn.linear_model` können wir ein Lineare Regression erstellen. \n",
    "\n",
    "Diese Lineare Regression wird in der Variable `lm` gespeichert. Anschließend wird die Methode `fit()` aufgerufen, um das Modell zu trainieren. Als Argumente werden die unabhängigen Variablen `X_train` und die abhängige Variable `y_train` übergeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im nächsten Schritt werden wir die Vorhersagen des Modells auf dem Testdatensatz berechnen und die tatsächlichen Werte mit den vorhergesagten Werten vergleichen.\n",
    "Daher werden wir die Methode `predict()` verwenden, um die Vorhersagen zu berechnen.\n",
    "\n",
    "- Im nächsten Schritt zeigt der Code die ersten 5 Vorhersagen an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred[:5] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um das Model zu evaluieren, mehrere Metriken wie die Koeffizienten wie Slope aber den Intercept bestimmen. \n",
    "Diese Methode gibt den Bestimmtheitsmaß R² zurück, welches angibt, wie gut die unabhängigen Variablen die abhängige Variable erklären können.\n",
    "\n",
    "Dabei können wir: \n",
    "- Koeffizienten\n",
    "- Intercept\n",
    "- R2\n",
    "- Mean squared Error (MSE) \n",
    "uns ausgeben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Ausgabe der Koeffizienten der Regressionsgleichung\n",
    "cdf = pd.DataFrame(model.coef_, X.columns, columns=[\"Coef\"])\n",
    "print(cdf)\n",
    "\n",
    "\n",
    "# Ausgabe des Achsenabschnitts (Intercept), d.h. der Wert, bei dem die unabhängigen Variablen 0 sind\n",
    "print(\"Achsenabschnitt (Intercept):\", model.intercept_)\n",
    "\n",
    "# Berechnung des R²-Wertes zur Bewertung des Modells\n",
    "r2_score = r2_score(y_test, y_pred)\n",
    "print(\"Bestimmtheitsmaß (R²) auf dem Testdatensatz:\", r2_score)\n",
    "\n",
    "# Berechnung des Mittleren Quadratischen Fehlers (Mean Squared Error, MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mittlerer Quadratischer Fehler (Mean Squared Error, MSE):\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test, y_pred, color=\"blue\", label=\"Vorhersagen\")\n",
    "plt.xlabel(\"Tatsächliche Werte\")\n",
    "plt.ylabel(\"Vorhergesagte Werte\")\n",
    "plt.title(\"Tatsächliche vs. Vorhergesagte Werte\")\n",
    "plt.legend()\n",
    "\n",
    "# Plot der Regressionslinie\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color=\"red\", linewidth=2, label=\"Regressionslinie\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachdem wir die Regression erstellt haben könne wir die Regression Testen, indem wir \n",
    "eigene Werte eingeben um die Löhne zu berechnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "educ = 12\n",
    "exper = 1\n",
    "metro = 0\n",
    "\n",
    "\n",
    "prediction = model.intercept_ + model.coef_[0] * educ + model.coef_[1] * exper + model.coef_[2] * metro\n",
    "print(f\"Die vorhergesagte Lohnhöhe für eine Person mit {educ} Jahren Bildung, {exper} Jahren Erfahrung und dem Metro-Status {metro} beträgt: {prediction:.2f} USD.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4 Statsmodel\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine weitere Libary die ich empfehlen kann ist die Statsmodels Libary. Diese Libary bietet dir eine Vielzahl an statistischen Funktionen und Modellen. Hier ein kleines Beispiel wie du die OLS Regression mit Statsmodels durchführen kannst. Ebenso ist es möglich mit weniger Code mehr ausgaben zu erhalten\n",
    "Hier werden auch viele ähnlichkeiten zusehen sein wie in ***R***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um eine Regression durchzuführen, müssen wir eine Konstante hinzufügen, da die Statsmodels-Bibliothek keine Konstante hinzufügt.\n",
    "1. da wir die Libary mit sm abkürzen, können wir die Konstante mit `sm.add_constant(X)` hinzufügen.\n",
    "2. Anschließend erstellen wir das Modell mit `sm.OLS(y_train, X_train_const)` und fitten es mit `fit()`.\n",
    "3. Mit `summary()` können wir uns die Ergebnisse anzeigen lassen.\n",
    "4. und geben uns die ergebnise aus mit `results.summary()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_const = sm.add_constant(X_train)\n",
    "X_test_const = sm.add_constant(X_test)\n",
    "\n",
    "model_stats = sm.OLS(y_train, X_train_const)\n",
    "results = model_stats.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachdem wir das Modell mit den Trainingsdaten trainiert haben, können wir es verwenden, um Vorhersagen für die Testdaten zu treffen und die Leistung des Modells zu bewerten.\n",
    "\n",
    "\n",
    "Dies erreichen wird durch `results.predict` mit den **Test** Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_statsmodel = results.predict(X_test_const)\n",
    "\n",
    "print(\"Vorhersagen für die Testdaten:\", y_pred_statsmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun können wir die Vorhersagen mit den tatsächlichen Werten vergleichen und die Modellgüte bewerten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "mse = mean_squared_error(y_test, y_pred_statsmodel)\n",
    "r2 = r2_score(y_test, y_pred_statsmodel)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Bestimmtheitsmaß (R²):\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im nächsten abschnitt werden to Zentralen Metriken extrahiert um Vorhersagen zu treffen an eigene Werten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "coef_statsmodel = results.params  # Koeffizienten für educ, exper und metro\n",
    "intercept = results.params[0]  # Achsenabschnitt (Intercept)\n",
    "\n",
    "# Vorhersage berechnen\n",
    "formula = f'wage = {intercept:.3f} + {coef_statsmodel[1]:.3f} * educ + {coef_statsmodel[2]:.3f} * exper + {coef_statsmodel[3]:.3f} * metro'\n",
    "print(formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "educ_statsmodel = 14\n",
    "exper_statsmodel = 2\n",
    "metro_statsmodel = 1\n",
    "\n",
    "prediction_statsmodel = intercept + coef_statsmodel[0] * educ_statsmodel + coef_statsmodel[1] * exper_statsmodel + coef_statsmodel[2] * metro_statsmodel\n",
    "\n",
    "print(f\"Die vorhergesagte Lohnhöhe beträgt: {prediction_statsmodel:.2f} USD.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_pred = results.predict()\n",
    "list_pred[:5], y_pred[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
